---                                                                                                                                                             
layout: post
title: "【Cuda】入门和gpu相关知识"
description: "最开始看的一些关于cuda的基本知识"
category: 'programming languages'
---

#####1.关于GPU

GPU是图形处理单元(Graphic Processing Unit)的简称，用多个GPU处理器来并行计算

#####2.Cuda
	
cuda采用的是C/C++编译器为前端，以C/C++语法为基础设计，有片内共享存储器，CUDA软件栈包含两个层次，一个是驱动层的API,这类函数以cu开关，一个是运行层的API，以cuda开头，运行层API是建立在驱动层API之上的，是对驱动层API的封装，我们的开发都是优先使用运行时API，就说尽量用cuda开头的函数

#####3.Cuda语法

**函数类型限定符**，用来确定函数是在CPU还是在GPU上执行，以及这个函数是从CPU调用还是从GPU调用。

	__device__，__device__表示从GPU上调用，在GPU上执行；
	__global__，__global__表示在CPU上调用，在GPU上执行，也就是所谓的内核(kernel)函数；内核主要用来执行多线程调用。
	__host__，__host__表明在CPU上调用，在CPU上执行，这是默认时的情况，也就是传统的C函数。CUDA支持__host__和__device__的联用，表示同时为主机和设备编译。此时这个函数不能出现多线程语句

**变量类型限定符**，用来规定变量存储什么位置上。在传统的CPU程序上，这个任务由编译器承担。在CUDA中，不仅要使用主机端的内存，还要使用设备端的显存和GPU片上的寄存器、共享存储器和缓存。在CUDA存储器模型中，一共抽象出来了8种不同的存储器。复杂的存储器模型使得必须要使用限定符要说明变量的存储位置。

	__device__，__device__表明声明的数据存放在显存中，所有的线程都可以访问，而且主机也可以通过运行时库访问；
	__shared__，__shared__表示数据存放在共享存储器在，只有在所在的块内的线程可以访问，其它块内的线程不能访问；
	__constant__，__constant__表明数据存放在常量存储器中，可以被所有的线程访问，也可以被主机通过运行时库访问；

如果在GPU上执行的函数内部的变量没有限定符，那表示它存放在寄存器或者本地存储器中，在寄存器中的数据只归线程所有，其它线程不可见。如果SM的寄存器用完，那么编译器就会将本应放到寄存器中的变量放到本地存储器中。

执行配置运算符<<< >>>，用来传递内核函数的执行参数。执行配置有四个参数，第一个参数声明网格的大小，第二个参数声明块的大小，第三个参数声明动态分配的共享存储器大小，默认为0，最后一个参数声明执行的流，默认为0。

**内建变量**，用于在运行时获得网格和块的尺寸及线程索引等信息

	gridDim, gridDim是一个包含三个元素x,y,z的结构体，分别表示网格在x,y,z三个方向上的尺寸，虽然其有三维，但是目前只能使用二维；
	blockDim, blockDim也是一个包含三个元素x,y,z的结构体，分别表示块在x,y,z三个方向上的尺寸，对应于执行配置中的第一个参数，对应于执行配置的第二个参数；
	blockIdx, blockIdx也是一个包含三个元素x,y,z的结构体，分别表示当前线程所在块在网格中x,y,z三个方向上的索引；
	threadIdx, threadIdx也是一个包含三个元素x,y,z的结构体，分别表示当前线程在其所在块中x,y,z三个方向上的索引；
	warpSize，warpSize表明warp的尺寸，在计算能力为1.0的设备中，这个值是24，在1.0以上的设备中，这个值是32。

其中__syncthreads()是CUDA的内置命令，其作用是保证block内的所有线程都已经运行到调用__syncthreads()的位置

CUDA程序的基本模式：

	分配内存空间和显存空间
	初始化内存空间
	将要计算的数据从内存上复制到显存上
	执行kernel计算
	将计算后显存上的数据复制到内存上
	处理复制到内存上的数据

#####4.CUDA编程模型

它支持大量的线程级并行计算，CUDA编程模型将CPU作为主机（Host），而将GPU做为协处理器（Coprocessor），或者设备（Device），以CPU来控制程序整体的串行逻辑和任务调度，而让GPU来运行一些能够被高度线程化的数据并行部分。即让GPU与CPU协同工作，更确切的说是CPU控制GPU工作。GPU只有在计算高度数据并行任务时才发挥作用。一般而言，ＣＵＤＡ并行程序包括串行计算部分和并行计算部分，并行计算部分称之为内核（Kernel），内核只是一个在ＧＰＵ上执行的数据并行代码段。理想情况下，串行代码的作用应该只是清理上个内核函数，并启动下一个内核函数。

#####5.CUDA线程层次

CUDA的关键特性：线程按照粗粒度的线程块和细粒度的线程两个层次进行组织、在细粒度并行的层次通过共享存储器和栅栏同步实现通信，这就是CUDA的双层线程模型。对于程序员来说，他们需要将任务划分为互不相干的粗粒度子问题(最好是易并行计算)，再将每个子问题划分为能够使用线程处理的问题。内核函数实质上是以块为单位执行的。

#####6.存储器组织

CUDA的存储器由一系列不同的地址空间组成。其中，shared memory和register位于GPU片内，Texture memory和Constant memory可以由GPU片内缓存加速对片外显存的访问，而Local memory和Device memory位于GPU片外的显存中

在kernel中不允许有C++的类、继承以及在基本块中定义变量等语法

fprintf 用于文件操作，

纹理存储器（texture memory）是一种只读存储器，由GPU用于纹理渲染的的图形专用单元发展而来，因此也提供了一些特殊功能。纹理存储器中的数据位于显存，但可以通过纹理缓存加速读取。在纹理存储器中可以绑定的数据比在常量存储器可以声明的64K大很多，并且支持一维、二维或者三维纹理。在通用计算中，纹理存储器十分适合用于实现图像处理或查找表，并且对数据量较大时的随机数据访问或者非对齐访问也有良好的加速效果。




























参考：[http://blog.csdn.net/maosong00/article/details/16828399](http://blog.csdn.net/maosong00/article/details/16828399)
